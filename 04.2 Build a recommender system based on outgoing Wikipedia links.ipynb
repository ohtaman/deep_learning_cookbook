{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Input, Reshape\n",
    "from tensorflow.keras.layers import Dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wp_movies_10k.ndjson') as fin:\n",
    "    movies = [json.loads(l) for l in fin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rotten Tomatoes', 9393),\n",
       " ('Category:English-language films', 5882),\n",
       " ('Category:American films', 5867)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_counts = Counter()\n",
    "for movie in movies:\n",
    "    link_counts.update(movie[2])\n",
    "link_counts.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  3回以上現れた link を抽出\n",
    "top_links = [link for link, c in link_counts.items() if c >= 3]\n",
    "\n",
    "# リンクと映画からインデックスを逆引きできるようにしておく\n",
    "link_to_idx = {link: idx for idx, link in enumerate(top_links)}\n",
    "movie_to_idx = {movie[0]: idx for idx, movie in enumerate(movies)}\n",
    "\n",
    "pairs = []\n",
    "for movie in movies:\n",
    "    pairs.extend((link_to_idx[link], movie_to_idx[movie[0]]) for link in movie[2] if link in link_to_idx)\n",
    "pairs_set = set(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949544, 66913, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs), len(top_links), len(movie_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "link (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "link_embedding (Embedding)      (None, 1, 50)        3345650     link[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "movie_embedding (Embedding)     (None, 1, 50)        500000      movie[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_product (Dot)               (None, 1, 1)         0           link_embedding[0][0]             \n",
      "                                                                 movie_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1)            0           dot_product[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 3,845,650\n",
      "Trainable params: 3,845,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def movie_embedding_model(embedding_size=50):\n",
    "    link = Input(name='link', shape=(1,))\n",
    "    movie = Input(name='movie', shape=(1,))\n",
    "    \n",
    "    link_embedding = Embedding(name='link_embedding', \n",
    "                               input_dim=len(top_links), \n",
    "                               output_dim=embedding_size)(link)\n",
    "    movie_embedding = Embedding(name='movie_embedding', \n",
    "                                input_dim=len(movie_to_idx), \n",
    "                                output_dim=embedding_size)(movie)\n",
    "    dot = Dot(name='dot_product', normalize=True, axes=2)([link_embedding, movie_embedding])\n",
    "    merged = Reshape((1,))(dot)\n",
    "    \n",
    "    model = Model(inputs=[link, movie], outputs=[merged])\n",
    "    model.compile(optimizer='nadam', loss='mse')\n",
    "    return model\n",
    "\n",
    "model = movie_embedding_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(5)\n",
    "\n",
    "def batchifier(pairs, positive_samples=50, negative_ratio=10):\n",
    "    batch_size = positive_samples * (1 + negative_ratio)\n",
    "    batch = np.zeros((batch_size, 3))\n",
    "    \n",
    "    while True:\n",
    "        for idx, (link_id, movie_id) in enumerate(random.sample(pairs, positive_samples)):\n",
    "            batch[idx, :] = (link_id, movie_id, 1)\n",
    "        idx = positive_samples\n",
    "\n",
    "        while idx < batch_size:\n",
    "            movie_id = random.randrange(len(movie_to_idx))\n",
    "            link_id = random.randrange(len(top_links))\n",
    "            if not (link_id, movie_id) in pairs_set:\n",
    "                batch[idx, :] = (link_id, movie_id, -1)\n",
    "                idx += 1\n",
    "\n",
    "        np.random.shuffle(batch)\n",
    "        yield {'link': batch[:, 0], 'movie': batch[:, 1]}, batch[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'link': array([31254.,  3801., 32643., 32318., 48731., 20558., 22418.,  1313.,\n",
       "         13365.]),\n",
       "  'movie': array([5530., 5874., 7628., 7685., 1854.,  849., 1529., 7236., 6238.])},\n",
       " array([ 1., -1., -1., -1., -1., -1.,  1.,  1., -1.]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(batchifier(pairs, positive_samples=3, negative_ratio=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1854/1854 - 48190s - loss: 0.5236\n",
      "Epoch 2/15\n",
      "1854/1854 - 87s - loss: 0.2376\n",
      "Epoch 3/15\n",
      "1854/1854 - 87s - loss: 0.2277\n",
      "Epoch 4/15\n",
      "1854/1854 - 88s - loss: 0.2243\n",
      "Epoch 5/15\n",
      "1854/1854 - 88s - loss: 0.2225\n",
      "Epoch 6/15\n",
      "1854/1854 - 87s - loss: 0.2204\n",
      "Epoch 7/15\n",
      "1854/1854 - 88s - loss: 0.2207\n",
      "Epoch 8/15\n",
      "1854/1854 - 88s - loss: 0.2210\n",
      "Epoch 9/15\n",
      "1854/1854 - 88s - loss: 0.2204\n",
      "Epoch 10/15\n",
      "1854/1854 - 88s - loss: 0.2203\n",
      "Epoch 11/15\n",
      "1854/1854 - 88s - loss: 0.2211\n",
      "Epoch 12/15\n",
      "1854/1854 - 88s - loss: 0.2209\n",
      "Epoch 13/15\n",
      "1854/1854 - 88s - loss: 0.2202\n",
      "Epoch 14/15\n",
      "1854/1854 - 88s - loss: 0.2211\n",
      "Epoch 15/15\n",
      "1854/1854 - 88s - loss: 0.2212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f10f36442b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_samples_per_batch = 512\n",
    "\n",
    "model.fit_generator(\n",
    "    batchifier(pairs, positive_samples=positive_samples_per_batch, negative_ratio=10),\n",
    "    epochs=15,\n",
    "    steps_per_epoch=len(pairs) // positive_samples_per_batch,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Rogue One 0.99999994\n",
      "19 Interstellar (film) 0.97400594\n",
      "245 Gravity (film) 0.9713407\n",
      "25 Star Wars sequel trilogy 0.96186566\n",
      "3349 Star Wars: The Force Awakens 0.96114933\n",
      "101 Prometheus (2012 film) 0.95846266\n",
      "659 Rise of the Planet of the Apes 0.9571362\n",
      "37 Avatar (2009 film) 0.95703185\n",
      "62 Fantastic Beasts and Where to Find Them (film) 0.9515644\n",
      "181 Pacific Rim (film) 0.9513081\n"
     ]
    }
   ],
   "source": [
    "movie_embedding = model.get_layer('movie_embedding')\n",
    "movie_weights = movie_embedding.get_weights()[0]\n",
    "movie_lengths = np.linalg.norm(movie_weights, axis=1)\n",
    "normalized_movie_embedding = (movie_weights.T / movie_lengths).T\n",
    "\n",
    "def similar_movies(movie):\n",
    "    dists = np.dot(normalized_movie_embedding, normalized_movie_embedding[movie_to_idx[movie]])\n",
    "    closest = np.argsort(dists)[-10:]\n",
    "    for c in reversed(closest):\n",
    "        print(c, movies[c][0], dists[c])\n",
    "\n",
    "similar_movies('Rogue One')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = ['Star Wars: The Force Awakens', 'The Martian (film)', 'Tangerine (film)', 'Straight Outta Compton (film)',\n",
    "        'Brooklyn (film)', 'Carol (film)', 'Spotlight (film)']\n",
    "worst = ['American Ultra', 'The Cobbler (2014 film)', 'Entourage (film)', 'Fantastic Four (2015 film)',\n",
    "         'Get Hard', 'Hot Pursuit (2015 film)', 'Mortdecai (film)', 'Serena (2014 film)', 'Vacation (2015 film)']\n",
    "\n",
    "y = np.asarray([1 for _ in best] + [0 for _ in worst])\n",
    "x = np.asarray([normalized_movie_embedding[movie_to_idx[movie]] for movie in best + worst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best:\n",
      "481 The Devil Wears Prada (film) 1.3734077878642066\n",
      "66 Skyfall 1.3071895358113084\n",
      "458 Hugo (film) 1.1964433597583484\n",
      "307 Les Misérables (2012 film) 1.1901157678426555\n",
      "939 Changeling (film) 1.120875228619155\n",
      "worst:\n",
      "1878 The Little Rascals (film) -1.636526204767615\n",
      "5097 Ready to Rumble -1.636464345542086\n",
      "9595 Speed Zone -1.6181485998840797\n",
      "6388 Bring It On Again -1.6147815272647175\n",
      "5092 Extreme Movie -1.587607458439102\n"
     ]
    }
   ],
   "source": [
    "estimated_movie_ratings = clf.decision_function(normalized_movie_embedding)\n",
    "best = np.argsort(estimated_movie_ratings)\n",
    "\n",
    "print('best:')\n",
    "for c in reversed(best[-5:]):\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])\n",
    "\n",
    "print('worst:')\n",
    "for c in best[:5]:\n",
    "    print(c, movies[c][0], estimated_movie_ratings[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_y = np.asarray([float(movie[-2][:-1]) / 100 for movie in movies if movie[-2]])\n",
    "rotten_x = np.asarray([normalized_movie_embedding[movie_to_idx[movie[0]]] for movie in movies if movie[-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_CUT_OFF = int(len(rotten_x) * 0.8)\n",
    "regr = LinearRegression()\n",
    "regr.fit(rotten_x[:TRAINING_CUT_OFF], rotten_y[:TRAINING_CUT_OFF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean squared error 0.06'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (regr.predict(rotten_x[TRAINING_CUT_OFF:]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean squared error %2.2f' % np.mean(error ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean squared error 0.09'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (np.mean(rotten_y[:TRAINING_CUT_OFF]) - rotten_y[TRAINING_CUT_OFF:])\n",
    "'mean squared error %2.2f' % np.mean(error ** 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
