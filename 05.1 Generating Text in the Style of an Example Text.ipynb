{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import json\n",
    "import os, sys\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import get_file\n",
    "import tensorflow.keras.callbacks\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import PIL\n",
    "from PIL import ImageDraw\n",
    "from IPython.display import clear_output, Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5592892"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = get_file('shakespeare', 'https://storage.googleapis.com/deep-learning-cookbook/100-0.txt')\n",
    "shakespeare = open(path).read()\n",
    "training_text = shakespeare.split('\\nTHE END', 1)[-1]\n",
    "\n",
    "len(training_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = list(sorted(set(training_text)))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1007 13:20:57.976240 140688087127680 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7ff3ec41e828>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W1007 13:20:58.744821 140688087127680 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7ff3dc0574a8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, None, 97)]        0         \n",
      "_________________________________________________________________\n",
      "unified_lstm (UnifiedLSTM)   (None, None, 640)         1889280   \n",
      "_________________________________________________________________\n",
      "unified_lstm_1 (UnifiedLSTM) (None, None, 640)         3279360   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 97)          62177     \n",
      "=================================================================\n",
      "Total params: 5,230,817\n",
      "Trainable params: 5,230,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def char_rnn_model(num_chars, num_layers, num_nodes=512, dropout=0.1):\n",
    "    input = Input(shape=(None, num_chars), name='input')\n",
    "    prev = input\n",
    "    for i in range(num_layers):\n",
    "        prev = LSTM(num_nodes, return_sequences=True)(prev)\n",
    "    dense = TimeDistributed(Dense(num_chars, name='dense',\n",
    "                                  activation='softmax'))(prev)\n",
    "    \n",
    "    model = Model(inputs=[input], outputs=[dense])\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = char_rnn_model(len(chars), num_layers=2, num_nodes=640, dropout=0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]),\n",
       " array([[[0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHUNK_SIZE = 160\n",
    "\n",
    "def data_generator(all_text, char_to_idx, batch_size, chunk_size):\n",
    "    x = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    y = np.zeros((batch_size, chunk_size, len(char_to_idx)))\n",
    "    \n",
    "    while True:\n",
    "        for row in range(batch_size):\n",
    "            idx = random.randrange(len(all_text) - chunk_size - 1)\n",
    "            chunk = np.zeros((chunk_size + 1, len(char_to_idx)))\n",
    "            for i in range(chunk_size + 1):\n",
    "                chunk[i, char_to_idx[all_text[idx + i]]] = 1\n",
    "            x[row, :, :] = chunk[:chunk_size]\n",
    "            y[row, :, :] = chunk[1:]\n",
    "        yield x, y\n",
    "\n",
    "next(data_generator(training_text, char_to_idx, 4, chunk_size=CHUNK_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 13:20:59.151643 140688087127680 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7ff3de89dd30>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W1007 13:20:59.422655 140688087127680 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7ff3a850a358>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "273/273 - 62s - loss: 3.3544 - accuracy: 0.2069\n",
      "Epoch 2/40\n",
      "273/273 - 61s - loss: 3.0698 - accuracy: 0.2424\n",
      "Epoch 3/40\n",
      "273/273 - 61s - loss: 2.1071 - accuracy: 0.4638\n",
      "Epoch 4/40\n",
      "273/273 - 61s - loss: 1.8408 - accuracy: 0.5343\n",
      "Epoch 5/40\n",
      "273/273 - 61s - loss: 1.7962 - accuracy: 0.5480\n",
      "Epoch 6/40\n",
      "273/273 - 61s - loss: 1.7685 - accuracy: 0.5567\n",
      "Epoch 7/40\n",
      "273/273 - 61s - loss: 1.7560 - accuracy: 0.5619\n",
      "Epoch 8/40\n",
      "273/273 - 61s - loss: 1.7291 - accuracy: 0.5692\n",
      "Epoch 9/40\n",
      "273/273 - 61s - loss: 1.7363 - accuracy: 0.5703\n",
      "Epoch 10/40\n",
      "273/273 - 61s - loss: 1.7322 - accuracy: 0.5725\n",
      "Epoch 11/40\n",
      "273/273 - 61s - loss: 1.7331 - accuracy: 0.5744\n",
      "Epoch 12/40\n",
      "273/273 - 61s - loss: 1.7318 - accuracy: 0.5759\n",
      "Epoch 13/40\n",
      "273/273 - 61s - loss: 1.7504 - accuracy: 0.5739\n",
      "Epoch 14/40\n",
      "273/273 - 61s - loss: 1.7334 - accuracy: 0.5779\n",
      "Epoch 15/40\n",
      "273/273 - 61s - loss: 1.6814 - accuracy: 0.5888\n",
      "Epoch 16/40\n",
      "273/273 - 62s - loss: 1.7439 - accuracy: 0.5782\n",
      "Epoch 17/40\n",
      "273/273 - 62s - loss: 1.7536 - accuracy: 0.5774\n",
      "Epoch 18/40\n",
      "273/273 - 61s - loss: 1.7649 - accuracy: 0.5760\n",
      "Epoch 19/40\n",
      "273/273 - 61s - loss: 1.6478 - accuracy: 0.5993\n",
      "Epoch 20/40\n",
      "273/273 - 61s - loss: 1.6801 - accuracy: 0.5945\n",
      "Epoch 21/40\n",
      "273/273 - 61s - loss: 1.6365 - accuracy: 0.6036\n",
      "Epoch 22/40\n",
      "273/273 - 62s - loss: 1.7126 - accuracy: 0.5900\n",
      "Epoch 23/40\n",
      "273/273 - 62s - loss: 1.6657 - accuracy: 0.5996\n",
      "Epoch 24/40\n",
      "273/273 - 61s - loss: 1.6574 - accuracy: 0.6021\n",
      "Epoch 25/40\n",
      "273/273 - 61s - loss: 1.6285 - accuracy: 0.6085\n",
      "Epoch 26/40\n",
      "273/273 - 61s - loss: 1.6302 - accuracy: 0.6091\n",
      "Epoch 27/40\n",
      "273/273 - 61s - loss: 1.6181 - accuracy: 0.6121\n",
      "Epoch 28/40\n",
      "273/273 - 61s - loss: 1.6596 - accuracy: 0.6051\n",
      "Epoch 29/40\n",
      "273/273 - 62s - loss: 1.6435 - accuracy: 0.6095\n",
      "Epoch 32/40\n",
      "273/273 - 62s - loss: 1.6350 - accuracy: 0.6122\n",
      "Epoch 33/40\n",
      "273/273 - 62s - loss: 1.6104 - accuracy: 0.6175\n",
      "Epoch 34/40\n",
      "273/273 - 62s - loss: 1.6095 - accuracy: 0.6185\n",
      "Epoch 35/40\n",
      "273/273 - 61s - loss: 1.6036 - accuracy: 0.6202\n",
      "Epoch 36/40\n",
      "273/273 - 62s - loss: 1.6982 - accuracy: 0.6021\n",
      "Epoch 37/40\n",
      "273/273 - 62s - loss: 1.6702 - accuracy: 0.6081\n",
      "Epoch 38/40\n",
      "273/273 - 62s - loss: 1.6034 - accuracy: 0.6217\n",
      "Epoch 39/40\n",
      "273/273 - 61s - loss: 1.5790 - accuracy: 0.6271\n",
      "Epoch 40/40\n",
      "273/273 - 62s - loss: 1.5714 - accuracy: 0.6291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3a8173780>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHUNK_SIZE = 160\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "#                               min_delta=0.03,\n",
    "#                               patience=3,\n",
    "#                               verbose=0, mode='auto')\n",
    "\n",
    "model = char_rnn_model(len(chars), num_layers=2, num_nodes=640, dropout=0)\n",
    "model.fit_generator(\n",
    "    data_generator(training_text, char_to_idx, batch_size=BATCH_SIZE, chunk_size=CHUNK_SIZE),\n",
    "    epochs=40,\n",
    "#     callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(training_text) // (BATCH_SIZE * CHUNK_SIZE),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- inputs --\n",
      "hundred voices of that sound.\n",
      "  FIRST CITIZEN. I twice five hundred, and their friends to piece\n",
      "    'em.\n",
      "  BRUTUS. Get you hence instantly, and tell those frien\n",
      "-- generated --\n",
      "ds\n",
      "    Which he did speak to me.\n",
      "    I have seen thee still as thou art,\n",
      "    And therefore have I seen thee in thy head,\n",
      "    And the devil have the worse of his desert.\n",
      "    The son of Caesar was a mort from him.\n",
      "    He hath not spoke to th' chaste and constant friend\n",
      "    Of the proverb with the best of all the treasure\n",
      "    Of the same prince and Clarence to his horse.\n",
      "    The sea hath struck the b"
     ]
    }
   ],
   "source": [
    "def generate_output(model, start_with, amount=400):\n",
    "    generated = start_with\n",
    "    \n",
    "    for i in range(amount):\n",
    "        x = np.zeros((1, len(generated), len(chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, char_to_idx[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = np.argmax(preds[len(generated) - 1])\n",
    "        next_char = chars[next_index]\n",
    "        yield next_char\n",
    "        \n",
    "        generated += next_char\n",
    "\n",
    "        \n",
    "start_index = random.randint(0, len(training_text) - CHUNK_SIZE - 1)\n",
    "fragment = training_text[start_index: start_index + CHUNK_SIZE]\n",
    "\n",
    "print('-- inputs --')\n",
    "print(fragment)\n",
    "print('-- generated --')\n",
    "for chunk in generate_output(model, fragment):\n",
    "    sys.stdout.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6章のために必要??\n",
    "with open('zoo/06/shakespeare.json', 'w') as fout:\n",
    "    json.dump({\n",
    "        'chars': ''.join(chars),\n",
    "        'char_to_idx': char_to_idx,\n",
    "        'chunk_size': CHUNK_SIZE,\n",
    "    }, fout)\n",
    "model.save('zoo/06/shakespeare.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1942"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_python(rootdir):\n",
    "    matches = []\n",
    "    for root, dirnames, filenames in os.walk(rootdir):\n",
    "        for fn in filenames:\n",
    "            if fn.endswith('.py'):\n",
    "                matches.append(os.path.join(root, fn))\n",
    "\n",
    "    return matches\n",
    "\n",
    "srcs = find_python(random.__file__.rsplit('/', 1)[0])\n",
    "len(srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(value):\n",
    "    if ' ' in value and sum(1 for ch in value if ch.isalpha()) > 6:\n",
    "        return 'MSG'\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print(\"hel\\\"lo\")\n",
      "print('MSG')\n",
      "this = \"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_literals(st):\n",
    "    res = []\n",
    "    start_text = start_quote = i = 0\n",
    "    quote = ''\n",
    "    while i < len(st):\n",
    "        if quote:\n",
    "            # 文字列リテラルが終了する場合\n",
    "            if st[i: i + len(quote)] == quote:\n",
    "                quote = ''\n",
    "                start_text = i\n",
    "                res.append(replacer(st[start_quote: i]))\n",
    "        elif st[i] in '\"\\'':\n",
    "            quote = st[i]\n",
    "            # 三連引用符の場合\n",
    "            if i < len(st) - 2 and st[i + 1] == st[i + 2] == quote:\n",
    "                quote = 3 * quote\n",
    "            start_quote = i + len(quote)\n",
    "            res.append(st[start_text: start_quote])\n",
    "        # 三連引用符でない場合、改行を含まない\n",
    "        if st[i] == '\\n' and len(quote) == 1:\n",
    "            start_text = i\n",
    "            res.append(quote)\n",
    "            quote = ''\n",
    "        # エスケープされている文字列は無視する\n",
    "        if st[i] == '\\\\':\n",
    "            i += 1\n",
    "        i += 1\n",
    "    return ''.join(res) + st[start_text:]\n",
    "\n",
    "print(replace_literals('print(\"hel\\\\\"lo\")'))\n",
    "print(replace_literals(\"print('hel\\\\'lo world')\"))\n",
    "print(replace_literals('this = \"wrong\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/test/badsyntax_pep3120.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/test/test_source_encoding.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/test/encoded_modules/module_iso_8859_1.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/test/encoded_modules/module_koi8_r.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/sqlite3/test/dbapi.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/sqlite3/test/factory.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/sqlite3/test/hooks.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/sqlite3/test/regression.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/sqlite3/test/transactions.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/sqlite3/test/types.py\n",
      "Could not read /home/mitsuhisa.ohta/.pyenv/versions/3.6.7/lib/python3.6/sqlite3/test/userfunctions.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21702736"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMMENT_RE = re.compile('#.*')\n",
    "python_code = []\n",
    "\n",
    "for fn in srcs:\n",
    "    try:\n",
    "        with open(fn, 'r') as fin:\n",
    "            src = fin.read()\n",
    "    except UnicodeDecodeError:\n",
    "        print('Could not read %s' % fn)\n",
    "    src = replace_literals(src)\n",
    "    src = COMMENT_RE.sub('', src)\n",
    "    python_code.append(src)\n",
    "\n",
    "python_code = '\\n\\n\\n'.join(python_code)\n",
    "len(python_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2759"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_chars = list(sorted(set(python_code)))\n",
    "py_char_to_idx = {ch: idx for idx, ch in enumerate(py_chars)}\n",
    "len(py_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 14:02:21.087583 140688087127680 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7ff3a8186780>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "W1007 14:02:21.366304 140688087127680 tf_logging.py:161] <tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7ff3de89d588>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, None, 2759)]      0         \n",
      "_________________________________________________________________\n",
      "unified_lstm_4 (UnifiedLSTM) (None, None, 640)         8704000   \n",
      "_________________________________________________________________\n",
      "unified_lstm_5 (UnifiedLSTM) (None, None, 640)         3279360   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 2759)        1768519   \n",
      "=================================================================\n",
      "Total params: 13,751,879\n",
      "Trainable params: 13,751,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "py_model = char_rnn_model(len(py_chars), num_layers=2, num_nodes=640, dropout=0)\n",
    "py_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1060/1059 - 1588s - loss: 3.2508 - accuracy: 0.3023\n",
      "Epoch 2/40\n",
      "1060/1059 - 1590s - loss: 3.1911 - accuracy: 0.3069\n",
      "Epoch 3/40\n",
      "1060/1059 - 1591s - loss: 3.1844 - accuracy: 0.3070\n",
      "Epoch 4/40\n",
      "1060/1059 - 1592s - loss: 3.1786 - accuracy: 0.3072\n",
      "Epoch 5/40\n",
      "1060/1059 - 1608s - loss: 3.1787 - accuracy: 0.3068\n",
      "Epoch 6/40\n",
      "1060/1059 - 1644s - loss: 3.1791 - accuracy: 0.3068\n",
      "Epoch 7/40\n",
      "1060/1059 - 1607s - loss: 3.1777 - accuracy: 0.3064\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f754eed3550d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# callbacks=[early,],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m )\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/envs/deep_learning_cookbook/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Early stopping に関する言及は本文中に存在しない\n",
    "\n",
    "# early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "#                               min_delta=0.03,\n",
    "#                               patience=3,\n",
    "#                               verbose=0, mode='auto')\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "py_model.fit_generator(\n",
    "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
    "    epochs=40,\n",
    "    # callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(model, start_with='\\ndef ', end_with='\\n\\n', diversity=1.0):\n",
    "    generated = \"\"\n",
    "    for ch in start_with:\n",
    "        yield ch\n",
    "        generated += ch\n",
    "    \n",
    "    for i in range(2000):\n",
    "        x = np.zeros((1, len(generated), len(py_chars)))\n",
    "        for t, char in enumerate(generated):\n",
    "            x[0, t, py_char_to_idx[char]] = 1.\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        \n",
    "        # 直近の生成結果を取得\n",
    "        preds = np.asarray(preds[len(generated) - 1]).astype(np.float64)\n",
    "        \n",
    "        # diversity を使って予測値をスケーリング\n",
    "        preds = np.log(preds) / diversity\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        \n",
    "        # スケーリングされた予測値をつかって、次の文字をサンプリング\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        next_index = np.argmax(probas)        \n",
    "        next_char = py_chars[next_index]\n",
    "        \n",
    "        yield next_char\n",
    "\n",
    "        generated += next_char\n",
    "        if generated.endswith(end_with):\n",
    "            break\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    st = \"\"\n",
    "    for ch in generate_code(py_model):\n",
    "        sys.stdout.write(ch)\n",
    "        st += ch\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここからネットワークの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "flat_model = char_rnn_model(len(py_chars), num_layers=1, num_nodes=512, dropout=0)\n",
    "flat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "#                               min_delta=0.03,\n",
    "#                               patience=3,\n",
    "#                               verbose=0, mode='auto')\n",
    "\n",
    "flat_model.fit_generator(\n",
    "    data_generator(python_code, py_char_to_idx, batch_size=BATCH_SIZE, chunk_size=160),\n",
    "    epochs=40,\n",
    "#     callbacks=[early,],\n",
    "    steps_per_epoch=2 * len(python_code) / (BATCH_SIZE * 160),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_code = 'if a == 2:\\n    b=1\\nelse:\\n    b=2\\n'\n",
    "\n",
    "def activations(model, code):\n",
    "    x = np.zeros((1, len(code), len(py_char_to_idx)))\n",
    "    for t, char in enumerate(code):\n",
    "        x[0, t, py_char_to_idx[char]] = 1.\n",
    "\n",
    "    output = model.get_layer('unified_lstm_5').output\n",
    "    f = K.function(model.input, output)\n",
    "    return f(x)[0]\n",
    "\n",
    "act = activations(flat_model, example_code)\n",
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interesting_neurons(act):\n",
    "    res = []\n",
    "    for n in np.argmax(act, axis=-1):\n",
    "        if not n in res:\n",
    "            res.append(n)\n",
    "    return res\n",
    "\n",
    "neurons = interesting_neurons(act)\n",
    "len(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_neurons(neurons, code, act, cell_size=12):\n",
    "    # コードを表示するスペースを確保するため、高さを len(neurons) + 1 とする\n",
    "    img = np.full((len(neurons) + 1, len(code), 3), 128)\n",
    "    # act は activations 関数の戻り値。[0, 1]の範囲に収まるよう変換する\n",
    "    scores = (act[:, neurons].T + 1) / 2\n",
    "\n",
    "    # 値の小さいものは赤く\n",
    "    img[1:, :, 0] = 255 * (1 - scores)\n",
    "    # 値の大きいものは緑に\n",
    "    img[1:, :, 1] = 255 * scores\n",
    "\n",
    "    f = BytesIO()\n",
    "    img = scipy.misc.imresize(img, float(cell_size), interp='nearest')\n",
    "    pil_img = PIL.Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    for idx, ch in enumerate(code):\n",
    "        draw.text((idx * cell_size + 2, 0), ch)\n",
    "    pil_img.save(f, 'png')\n",
    "    return Image(data=f.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_for_code(code):\n",
    "    act = activations(flat_model, code)\n",
    "    neurons = interesting_neurons(act)\n",
    "    return visualize_neurons(neurons, code, act)\n",
    "\n",
    "display(image_for_code('if (a == 2) and ((b == 1) or (c==2)):'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
